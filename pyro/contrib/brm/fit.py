from collections import namedtuple, defaultdict

from pyro.contrib.brm.model import model_repr, parameter_names

Fit = namedtuple('Fit', ['run', 'code', 'data', 'model', 'posterior'])
Posterior = namedtuple('Posterior', ['samples', 'get_param'])

# The idea  is that `pyro_posterior` and  `pyro_get_param` capture the
# backend specific part of  processing posterior samples. Alternatives
# to this approach include:

# 1. Have each back end return an iterable of samples, where each
# sample is something like a dictionary holding all of the parameters
# of interest. (Effectively the backend would be returning the result
# of mapping `get_param` over every sample for every parameter.

# 2. Have each backend implement some kind of query interface,
# allowing things like `query.marginal('b').mean()`, etc.

def pyro_posterior(run):
    return Posterior(run.exec_traces, pyro_get_param)

# Extracts a value of interest (e.g. 'b', 'r_1', 'L_2', 'sigma') from
# a single sample.

# It's expected that this should support all parameter names returned
# by `parameter_names(model)` where `model` is the `Model` from which
# samples were drawn.
def pyro_get_param(sample, name):
    if name == 'b' or name.startswith('r_') or name.startswith('sd_'):
        return sample.nodes['_RETURN']['value'][name]
    else:
        return sample.nodes[name]['value']

# This aims to be generic/polymorphic, requiring only arithmetic
# operations and `sqrt` on values returned by `get_param`. The idea is
# that this might make it possible to support backends which
# potentially differ in the way they store samples, and perhaps in
# whether they use numpy or torch to represent vectors/matrices.

# TODO: Use Welford for better stability/single pass?
def marginals(fit):
    sums = defaultdict(float)
    params = parameter_names(fit.model)
    samples = fit.posterior.samples
    get_param = fit.posterior.get_param
    # We don't include Bessel's correction.
    N = len(samples)
    for sample in samples:
        for p in params:
            sums[p] += get_param(sample, p)
    means = {k: v / float(N) for k, v in sums.items()}
    diffs = defaultdict(float)
    for sample in samples:
        for p in params:
            diffs[p] += (get_param(sample, p) - means[p]) ** 2
    sds = {k: (v / float(N)).sqrt() for k, v in diffs.items()}
    return {p: (means[p], sds[p]) for p in params}

# TODO: Have this be generated by the `__repr__` method on `Fit`?
# Allowing users to `print(fit)` to see this?
def print_marginals_simple(fit):
    for name, (mean, sd) in marginals(fit).items():
        print('==================================================')
        print(name)
        print('-- mean ------------------------------------------')
        print(mean)
        print('-- stddev ----------------------------------------')
        print(sd)

# This relies on the assumption that all models make available the
# parameters described by the `parameters` function in model.py, and
# that each of these is a tensor/multi-dimensional array of the
# expected size.
def print_marginals(fit):
    # TODO: More robust table formatting. (This will currently break
    # when a mean or sd is > 10, for example.)
    row = '{:<15} {: .2f} {: .2f}'
    header = '{:<15} {:>5.5s} {:>5.5s}'.format('', 'mean', 'sd')
    mean_and_sd = marginals(fit)
    print(header)
    b_mean, b_sd = mean_and_sd['b']
    for coef, mean, sd in zip(fit.model.population.coefs, b_mean, b_sd):
        readable_name = 'b_{}'.format(coef)
        print(row.format(readable_name, mean, sd))
    for ix, group in enumerate(fit.model.groups):
        r_mean, r_sd = mean_and_sd['r_{}'.format(ix+1)]
        for i, level in enumerate(group.factor.levels):
            for j, coef in enumerate(group.coefs):
                readable_name = 'r_{}[{},{}]'.format(group.factor.name, level, coef)
                print(row.format(readable_name, r_mean[i, j], r_sd[i, j]))

    for param in fit.model.response.nonlocparams:
        param_mean, param_sd = mean_and_sd[param.name]
        print(row.format(param.name, param_mean[0], param_sd[0]))

def print_model(fit):
    print(model_repr(fit.model))
