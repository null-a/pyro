from collections import namedtuple, defaultdict

from pyro.contrib.brm.model import model_repr, parameter_names

Fit = namedtuple('Fit', ['run', 'code', 'data', 'model', 'posterior'])
Posterior = namedtuple('Posterior', ['samples', 'get_param'])

# The idea  is that `pyro_posterior` and  `pyro_get_param` capture the
# backend specific part of  processing posterior samples. Alternatives
# to this approach include:

# 1. Have each back end return an iterable of samples, where each
# sample is something like a dictionary holding all of the parameters
# of interest. (Effectively the backend would be returning the result
# of mapping `get_param` over every sample for every parameter.

# 2. Have each backend implement some kind of query interface,
# allowing things like `query.marginal('b').mean()`, etc.

def pyro_posterior(run):
    return Posterior(run.exec_traces, pyro_get_param)

# Extracts a value of interest (e.g. 'b', 'r_1', 'L_2', 'sigma') from
# a single sample.

# It's expected that this should support all parameter names returned
# by `parameter_names(model)` where `model` is the `Model` from which
# samples were drawn.
def pyro_get_param(sample, name):
    if name == 'b' or name.startswith('r_') or name.startswith('sd_'):
        return sample.nodes['_RETURN']['value'][name]
    else:
        return sample.nodes[name]['value']

# This aims to be generic/polymorphic, requiring only arithmetic
# operations and `sqrt` on values returned by `get_param`. The idea is
# that this might make it possible to support backends which
# potentially differ in the way they store samples, and perhaps in
# whether they use numpy or torch to represent vectors/matrices.

# TODO: Use Welford for better stability/single pass?
def marginals(fit):
    sums = defaultdict(float)
    params = parameter_names(fit.model)
    samples = fit.posterior.samples
    get_param = fit.posterior.get_param
    # We don't include Bessel's correction.
    N = len(samples)
    for sample in samples:
        for p in params:
            sums[p] += get_param(sample, p)
    means = {k: v / float(N) for k, v in sums.items()}
    diffs = defaultdict(float)
    for sample in samples:
        for p in params:
            diffs[p] += (get_param(sample, p) - means[p]) ** 2
    sds = {k: (v / float(N)).sqrt() for k, v in diffs.items()}
    return {p: (means[p], sds[p]) for p in params}

# TODO: Have this be generated by the `__repr__` method on `Fit`?
# Allowing users to `print(fit)` to see this?
def print_marginals(fit):
    for name, (mean, sd) in marginals(fit).items():
        print('==================================================')
        print(name)
        print('-- mean ------------------------------------------')
        print(mean)
        print('-- stddev ----------------------------------------')
        print(sd)

def print_model(fit):
    print(model_repr(fit.model))
