from collections import namedtuple, defaultdict

from pyro.contrib.brm.model import model_repr, parameter_names

Fit = namedtuple('Fit', ['run', 'code', 'data', 'model', 'posterior'])
Posterior = namedtuple('Posterior', ['samples', 'get_param'])

# The idea  is that `pyro_posterior` and  `pyro_get_param` capture the
# backend specific part of  processing posterior samples. Alternatives
# to this approach include:

# 1. Have each back end return an iterable of samples, where each
# sample is something like a dictionary holding all of the parameters
# of interest. (Effectively the backend would be returning the result
# of mapping `get_param` over every sample for every parameter.

# 2. Have each backend implement some kind of query interface,
# allowing things like `query.marginal('b').mean()`, etc.

def pyro_posterior(run):
    return Posterior(run.exec_traces, pyro_get_param)

# Extracts a value of interest (e.g. 'b', 'r_1', 'L_2', 'sigma') from
# a single sample.

# It's expected that this should support all parameter names returned
# by `parameter_names(model)` where `model` is the `Model` from which
# samples were drawn.
def pyro_get_param(sample, name):
    if name == 'b' or name.startswith('r_') or name.startswith('sd_'):
        return sample.nodes['_RETURN']['value'][name]
    else:
        return sample.nodes[name]['value']

# This aims to be generic/polymorphic, requiring only arithmetic
# operations and `sqrt` on values returned by `get_param`. The idea is
# that this might make it possible to support backends which
# potentially differ in the way they store samples, and perhaps in
# whether they use numpy or torch to represent vectors/matrices.

# TODO: Use Welford for better stability/single pass?
def marginals(fit):
    sums = defaultdict(float)
    params = parameter_names(fit.model)
    samples = fit.posterior.samples
    get_param = fit.posterior.get_param
    # We don't include Bessel's correction.
    N = len(samples)
    for sample in samples:
        for p in params:
            sums[p] += get_param(sample, p)
    means = {k: v / float(N) for k, v in sums.items()}
    diffs = defaultdict(float)
    for sample in samples:
        for p in params:
            diffs[p] += (get_param(sample, p) - means[p]) ** 2
    sds = {k: (v / float(N)).sqrt() for k, v in diffs.items()}
    # TODO: Combine into single dict. (Otherwise consumer have to
    # assume both dicts have same set of keys.)
    return means, sds


def print_marginals2(fit):
    means, sds = marginals(fit)
    for name in means.keys():
        print('==================================================')
        print(name)
        print('-- mean ------------------------------------------')
        print(means[name])
        print('-- stddev ----------------------------------------')
        print(sds[name])


# TODO: Have this be generated by the `__repr__` method on `Fit`?
# Allowing users to `print(fit)` to see this?
def print_marginals(fit):
    assert type(fit) == Fit

    # Looking at only the first trace is OK here because the models
    # described by lme4 have static structure.
    trace = fit.run.exec_traces[0]

    # Is there a more Pyronic (not poking in trace internals) way to
    # achieve this? Or is it safer the have `genmodel` return a list
    # of sample sites used by the models it generates?
    sample_sites = [k for k in trace.nodes.keys()
                    if trace.nodes[k]['type'] == 'sample' and not k in ['obs', 'y']]
    marginal = fit.run.marginal(sample_sites)
    for name in sample_sites:
        print('==================================================')
        print(name)
        print('-- mean ------------------------------------------')
        print(marginal.empirical[name].mean)
        print('-- stddev ----------------------------------------')
        print(marginal.empirical[name].stddev)

def print_model(fit):
    print(model_repr(fit.model))
